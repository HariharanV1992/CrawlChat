name: Test Enhanced Crawler

on:
  pull_request:
    branches: [ main ]
    paths:
      - "crawlchat-service/crawler-service/**"
  workflow_dispatch:

env:
  AWS_REGION: ap-south-1

jobs:
  test-enhanced-crawler:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        echo "üì¶ Installing dependencies..."
        cd crawlchat-service/crawler-service
        pip install -r requirements.txt
        echo "‚úÖ Dependencies installed"
    
    - name: Test Enhanced Crawler Service
      env:
        SCRAPINGBEE_API_KEY: ${{ secrets.SCRAPINGBEE_API_KEY }}
      run: |
        echo "üß™ Testing Enhanced Crawler Service..."
        cd crawlchat-service/crawler-service
        
        # Test import
        python -c "
        import sys
        sys.path.insert(0, 'src')
        from crawler.enhanced_crawler_service import EnhancedCrawlerService
        print('‚úÖ Enhanced crawler service imported successfully')
        "
        
        # Test basic functionality
        python -c "
        import sys
        import os
        sys.path.insert(0, 'src')
        from crawler.enhanced_crawler_service import EnhancedCrawlerService
        
        api_key = os.getenv('SCRAPINGBEE_API_KEY')
        if not api_key:
            print('‚ùå SCRAPINGBEE_API_KEY not set')
            exit(1)
        
        service = EnhancedCrawlerService(api_key)
        print('‚úÖ Enhanced crawler service initialized')
        
        # Test single page crawl
        result = service.crawl_with_max_docs('https://example.com', max_doc_count=1)
        print(f'‚úÖ Single page crawl test: {result.get(\"success\")}')
        print(f'Documents found: {result.get(\"documents_found\")}')
        "
        
        echo "‚úÖ Enhanced crawler service tests passed"
    
    - name: Test Lambda Handler
      env:
        SCRAPINGBEE_API_KEY: ${{ secrets.SCRAPINGBEE_API_KEY }}
      run: |
        echo "üß™ Testing Lambda Handler..."
        cd crawlchat-service/crawler-service
        
        # Test lambda handler import
        python -c "
        from lambda_handler import lambda_handler
        print('‚úÖ Lambda handler imported successfully')
        "
        
        # Test lambda handler with enhanced crawl
        python -c "
        import json
        from lambda_handler import lambda_handler
        
        # Test event
        event = {
            'url': 'https://example.com',
            'max_doc_count': 1
        }
        
        result = lambda_handler(event, None)
        print(f'‚úÖ Lambda handler test: {result.get(\"statusCode\")}')
        print(f'Response: {result.get(\"body\")[:200]}...')
        "
        
        echo "‚úÖ Lambda handler tests passed"
    
    - name: Test Docker Build
      run: |
        echo "üê≥ Testing Docker Build..."
        cd crawlchat-service
        
        # Test crawler service Docker build
        docker build -f crawler-service/Dockerfile -t test-crawler-service .
        
        if [ $? -eq 0 ]; then
          echo "‚úÖ Crawler service Docker build successful"
        else
          echo "‚ùå Crawler service Docker build failed"
          exit 1
        fi
        
        # Test lambda service Docker build
        docker build -f lambda-service/Dockerfile -t test-lambda-service .
        
        if [ $? -eq 0 ]; then
          echo "‚úÖ Lambda service Docker build successful"
        else
          echo "‚ùå Lambda service Docker build failed"
          exit 1
        fi
        
        echo "‚úÖ All Docker builds successful"
    
    - name: Validate Files
      run: |
        echo "üîç Validating required files..."
        
        # Check crawler service files
        if [ ! -f "crawlchat-service/crawler-service/Dockerfile" ]; then
          echo "‚ùå Crawler service Dockerfile not found"
          exit 1
        fi
        
        if [ ! -f "crawlchat-service/crawler-service/requirements.txt" ]; then
          echo "‚ùå Crawler service requirements.txt not found"
          exit 1
        fi
        
        if [ ! -f "crawlchat-service/crawler-service/lambda_handler.py" ]; then
          echo "‚ùå Crawler service lambda_handler.py not found"
          exit 1
        fi
        
        if [ ! -f "crawlchat-service/crawler-service/src/crawler/enhanced_crawler_service.py" ]; then
          echo "‚ùå Enhanced crawler service not found"
          exit 1
        fi
        
        # Check lambda service files
        if [ ! -f "crawlchat-service/lambda-service/Dockerfile" ]; then
          echo "‚ùå Lambda service Dockerfile not found"
          exit 1
        fi
        
        if [ ! -f "crawlchat-service/lambda-service/src/crawler/enhanced_crawler_service.py" ]; then
          echo "‚ùå Enhanced crawler service not found in lambda service"
          exit 1
        fi
        
        echo "‚úÖ All required files found"
    
    - name: Summary
      run: |
        echo "üéâ Enhanced Crawler Test Summary"
        echo "================================"
        echo "‚úÖ Enhanced crawler service implemented"
        echo "‚úÖ Lambda handler configured"
        echo "‚úÖ Docker builds working"
        echo "‚úÖ All files validated"
        echo ""
        echo "üöÄ Ready for deployment!" 